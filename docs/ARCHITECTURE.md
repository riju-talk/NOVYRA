# ðŸ— NOVYRA System Architecture

> Knowledge-Graph-Driven Adaptive Learning Infrastructure

---

## ðŸŽ¯ System Vision

**NOVYRA is not a chatbot. It's learning infrastructure.**

Traditional AI tutors:
- âŒ Retrieve information from vector stores
- âŒ Generate generic explanations
- âŒ No understanding of learning progression
- âŒ Black box decision making

NOVYRA:
- âœ… Structured knowledge graph with prerequisite relationships
- âœ… Adaptive reasoning based on learner's mastery state
- âœ… Explainable evaluation with confidence calibration
- âœ… Hybrid edge/cloud inference for scalability

---

## ðŸ“ 7-Layer Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER INTERFACE LAYER                     â”‚
â”‚  Question Interface â”‚ Study Planner â”‚ Community Forum      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              INTERACTION & INTENT ENGINE                    â”‚
â”‚  Intent Detection â”‚ Concept Extraction â”‚ Task Classificationâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         ADAPTIVE LEARNING INTELLIGENCE CORE                 â”‚
â”‚  Hint Ladder â”‚ Socratic Reasoning â”‚ Misconception Detectionâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              KNOWLEDGE GRAPH BRAIN (Neo4j)                  â”‚
â”‚  Concepts â”‚ Prerequisites â”‚ Mastery States â”‚ Dependencies   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           COMMUNITY INTELLIGENCE LAYER                      â”‚
â”‚  Concept Mapping â”‚ Quality Filtering â”‚ Reputation Weightingâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          EVALUATION & MASTERY ENGINE                        â”‚
â”‚  Rubric Grading â”‚ Confidence Calibration â”‚ Mastery Tracking â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    HYBRID AI RUNTIME (Cloud + AMD Edge)                     â”‚
â”‚  Graph-Aware RAG â”‚ Vector Search â”‚ NPU Inference Routing   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ§  Knowledge Graph Structure

### Node Types

```cypher
(:Concept {
  name: String,
  description: String,
  domain: String,
  difficulty: Integer
})

(:User {
  id: String,
  mastery_profile: Map
})
```

### Relationship Types

```cypher
// Prerequisite dependency
(Arrays)-[:PREREQUISITE_OF]->(Binary Search)

// Mastery tracking
(User)-[:MASTERED_BY {score: 0.8, updated: timestamp}]->(Concept)

// Failure tracking for intervention
(User)-[:STRUGGLES_WITH {attempts: 3}]->(Concept)

// Conceptual similarity
(BFS)-[:RELATED_TO {weight: 0.7}]->(DFS)

// Topic hierarchy
(Binary Search)-[:PART_OF]->(Searching Algorithms)
```

### Example Graph Query

```cypher
// Find learning path for weak concept
MATCH (user:User {id: $userId})-[r:MASTERED_BY]->(weak:Concept)
WHERE r.score < 0.5
MATCH path = (prereq:Concept)-[:PREREQUISITE_OF*]->(weak)
WHERE NOT EXISTS {
  (user)-[m:MASTERED_BY]->(prereq)
  WHERE m.score >= 0.7
}
RETURN prereq.name AS recommended_concept
ORDER BY prereq.difficulty ASC
LIMIT 5
```

---

## ðŸ”„ Complete Learning Flow

### User asks: "How does binary search work?"

```
1. INTENT DETECTION
   â†“ "explain" + "binary search"
   â†’ Task: conceptual explanation

2. CONCEPT IDENTIFICATION
   â†“ Extract: "Binary Search"
   â†’ Domain: Computer Science

3. KNOWLEDGE GRAPH QUERY
   â†“ Cypher: MATCH (c:Concept {name: "Binary Search"})
             MATCH (prereq)-[:PREREQUISITE_OF]->(c)
   â†’ Prerequisites: [Arrays, Linear Search]

4. USER MASTERY LOOKUP
   â†“ Check: User mastery of prerequisites
   â†’ Arrays: 0.4 (weak)
   â†’ Linear Search: 0.6 (okay)

5. CONTEXT ASSEMBLY
   â†“ Build enriched context:
   - Concept description
   - Prerequisites and their mastery
   - Related concepts
   - Common misconceptions
   - Community Q&A

6. STRUCTURED REASONING
   â†“ Gemini generates response with:
   - Prerequisite review (Arrays)
   - Step-by-step explanation
   - Hint ladder (hidden)
   - Misconception warnings
   - Practice problems

7. MASTERY UPDATE
   â†“ Record interaction:
   - Attempt logged
   - Confidence weight adjusted
   - Neo4j edge updated
   - Recommendation trigger if needed
```

---

## ðŸŽ¯ Adaptive Engine Logic

### Mastery Score Calculation

```python
mastery_score = (correct_attempts / total_attempts) * confidence_weight

confidence_weight = 1.0
  - hint_penalty (0.1 per hint used)
  - time_decay (days since last attempt > 7)
  - reattempt_penalty (frequency of failures)
```

### Recommendation Algorithm

```python
def get_learning_path(user_id, target_concept):
    # Get user's weak prerequisites
    weak_nodes = graph.query("""
        MATCH (u:User {id: $userId})-[r:MASTERED_BY]->(c:Concept)
        WHERE r.score < 0.5
        RETURN c
    """)
    
    # Find shortest path through weak nodes to target
    path = graph.shortest_path(
        start=weak_nodes[0],
        end=target_concept,
        relationship="PREREQUISITE_OF"
    )
    
    # Order by difficulty (easiest first)
    return sorted(path, key=lambda c: c.difficulty)
```

### Hint Ladder Generation

```python
def generate_hints(problem, difficulty):
    hints = []
    
    # Level 1: Concept reminder
    hints.append(f"Remember: {get_prerequisite_summary(problem)}")
    
    # Level 2: Approach hint
    hints.append(f"Think about: {get_approach_hint(problem)}")
    
    # Level 3: Partial solution
    hints.append(f"Try this step: {get_first_step(problem)}")
    
    # Level 4: Nearly complete
    hints.append(f"You're close! Now: {get_final_hint(problem)}")
    
    return hints[:difficulty]  # More hints for harder problems
```

---

## ðŸ”¬ Rubric-Aware Evaluation

### Rubric Structure

```json
{
  "rubric_name": "Binary Search Implementation",
  "criteria": [
    {
      "name": "Correctness",
      "weight": 0.4,
      "levels": [
        {"score": 4, "description": "Fully correct with edge cases"},
        {"score": 3, "description": "Correct for main cases"},
        {"score": 2, "description": "Logical errors present"},
        {"score": 1, "description": "Major misunderstanding"}
      ]
    },
    {
      "name": "Code Quality",
      "weight": 0.3,
      "levels": [...]
    },
    {
      "name": "Explanation",
      "weight": 0.3,
      "levels": [...]
    }
  ]
}
```

### Evaluation Process

```
1. Parse rubric into structured criteria
2. Extract dimensions (correctness, quality, explanation)
3. For each dimension:
   - LLM evaluates with JSON schema
   - Assigns level (1-4)
   - Provides evidence
4. Compute weighted total
5. Generate actionable feedback
6. Calibrate confidence (if model unsure, flag for human review)
```

---

## âš¡ AMD Edge Inference Architecture

### Decision Tree

```
Query arrives
    â†“
Is it simple (< 500 chars) AND realtime required?
    YES â†’ Route to AMD NPU (Edge)
    NO  â†“
Is it complex reasoning or needs latest knowledge?
    YES â†’ Route to Cloud (Gemini)
    NO  â†“
Route to Edge CPU (fallback)
```

### Edge Model Stack

```
1. Quantized ONNX Model (Phi-2 INT4)
   â”œâ”€ Model Size: 1.2 GB
   â”œâ”€ Latency: 50-100ms
   â””â”€ Use Case: Simple Q&A, definitions

2. AMD NPU Optimization (DirectML)
   â”œâ”€ Hardware: Ryzen AI NPU
   â”œâ”€ Performance: 40+ TOPS
   â””â”€ Power: 70% less than GPU

3. Cloud Fallback (Gemini 1.5 Flash)
   â”œâ”€ Latency: 800-1500ms
   â”œâ”€ Capability: Complex reasoning
   â””â”€ Cost: $0.0001/request
```

### Performance Metrics

| Metric | Cloud | Edge CPU | Edge NPU |
|--------|-------|----------|----------|
| Latency | 1200ms | 300ms | 80ms |
| Cost/1K requests | $0.10 | $0 | $0 |
| Quality | â˜…â˜…â˜…â˜…â˜… | â˜…â˜…â˜…â˜†â˜† | â˜…â˜…â˜…â˜…â˜† |
| Power | N/A | 25W | 5W |

---

## ðŸ“Š Data Flow & State Management

### State Stores

```
1. Neo4j (Knowledge Graph)
   - Concepts and their relationships
   - User mastery edges
   - Learning paths

2. PostgreSQL (Relational)
   - User profiles
   - Attempt history (audit log)
   - Rubric evaluations
   - Community posts/answers

3. In-Memory Cache (Redis)
   - Active session state
   - Frequent queries
   - Rate limiting

4. Vector Store (Pinecone) [Optional]
   - Semantic search for community content
   - Related concept discovery
```

### Consistency Model

```
Write Flow:
1. Transaction begins in PostgreSQL
2. Attempt logged (immutable record)
3. Async job updates Neo4j mastery edge
4. Cache invalidated
5. Frontend receives updated state

Read Flow:
1. Check Redis cache
2. If miss, query Neo4j for graph context
3. Join with PostgreSQL for detailed records
4. Cache result
5. Return to client
```

---

## ðŸ” Security & Privacy

### Data Protection

- âœ… User PII encrypted at rest (AES-256)
- âœ… API authentication via JWT tokens
- âœ… Rate limiting per user (100 req/min)
- âœ… Content moderation on submissions
- âœ… Audit logs for all evaluations

### AI Safety

- âœ… Gemini safety filters enabled
- âœ… Output validation against schema
- âœ… Confidence thresholds for auto-feedback
- âœ… Human-in-the-loop for low-confidence evaluations
- âœ… Version control on prompts

---

## ðŸ“ˆ Scalability Strategy

### Horizontal Scaling

```
Load Balancer
    â”œâ”€ API Server 1 (Stateless)
    â”œâ”€ API Server 2 (Stateless)
    â””â”€ API Server N (Stateless)
         â†“
    Neo4j Cluster (Read Replicas)
         â†“
    PostgreSQL Primary + Replicas
```

### Performance Targets

| Metric | Target | Current |
|--------|--------|---------|
| Graph Query | < 50ms | ~30ms |
| LLM Inference | < 2s | ~1.2s |
| End-to-End | < 3s | ~2.5s |
| Concurrent Users | 10K+ | Tested to 500 |

### Cost Optimization

- **Edge execution**: 60% of queries â†’ $0 cloud cost
- **Caching**: 40% cache hit rate â†’ 40% fewer LLM calls
- **Batch processing**: Nightly graph updates â†’ lower DB load
- **Auto-scaling**: Scale down during off-hours â†’ 30% compute savings

---

## ðŸŽ¯ Key Differentiators

### vs Traditional RAG Systems

| Feature | RAG | NOVYRA |
|---------|-----|--------|
| Context | Vector similarity | Prerequisite graph |
| Adaptation | Static | Mastery-aware |
| Evaluation | Heuristic | Rubric-based |
| Explainability | Low | High |
| Learning Path | None | Dynamic |

### vs Learning Management Systems (LMS)

| Feature | LMS | NOVYRA |
|---------|-----|--------|
| Content | Static courses | Dynamic concept graph |
| Personalization | Rule-based | AI-driven |
| Feedback | Delayed | Real-time |
| Intervention | Manual | Automatic |
| Scalability | Instructor-limited | Automated |

---

## ðŸš€ Future Enhancements

### Phase 2 (Post-Hackathon)

1. **Real-time Collaboration**
   - Peer learning sessions
   - Shared concept exploration

2. **Teacher Dashboard**
   - Class-level analytics
   - Intervention recommendations
   - Custom rubric builder

3. **Mobile App**
   - Offline learning with edge models
   - Push notifications for milestones

### Phase 3 (Production)

1. **Multi-modal Learning**
   - Image/video analysis
   - Voice interaction
   - Interactive simulations

2. **Advanced Analytics**
   - Predictive failure detection
   - Learning style identification
   - Curriculum optimization

3. **Enterprise Features**
   - SSO integration
   - LTI compliance for LMS integration
   - White-label deployment

---

## ðŸ“š Technical Stack Summary

**Backend:**
- Python 3.11, FastAPI
- Neo4j (Knowledge Graph)
- PostgreSQL (Relational Data)
- Redis (Caching)

**AI/ML:**
- Google Gemini 1.5 (LLM)
- AMD NPU (Edge Inference)
- ONNX Runtime (Model Serving)
- DirectML (AMD Optimization)

**Frontend:**
- Next.js 14, React
- TailwindCSS
- Prisma ORM

**Infrastructure:**
- Docker, Docker Compose
- Vercel (Frontend)
- Render (Backend)
- Neo4j Aura (Graph DB)

---

**This architecture positions NOVYRA as research-grade learning infrastructure, not just another AI tutor.**
